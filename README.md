# ğŸš€ Project Objective

Build an end-to-end mini-pipeline to measure marketing effectiveness across the full purchase cycle: ingestion and structuring of synthetic web logs, funnel definition, descriptive and predictive analyses, and setup of a local interactive dashboard (cost-free).

## ğŸ“… Detailed 1-week plan

```text
Day	Main tasks
Day 1	
â€¢ Initialize Git repo and virtual environment
â€¢ Collect/generate synthetic dataset (page-view, click, purchase logs)
Day 2	
â€¢ Ingest data into SQLite (or Pandas)
â€¢ Python scripts for cleaning and normalization
Day 3	
â€¢ Design the funnel (e.g.: visit â†’ add-to-cart â†’ purchase)
â€¢ Compute key metrics (conversion rate, drop-off)
Day 4	
â€¢ Simple predictive model (logistic regression) to estimate purchase probability
â€¢ Evaluation (AUC, confusion matrix)
Day 5	
â€¢ Simulate an A/B test (effect of a new feature) and measure impact
â€¢ Significance statistics (proportion test)
Day 6	
â€¢ Create a mini local dashboard with Plotly Dash or Streamlit
â€¢ Visualize KPIs and model results
Day 7	
â€¢ Write README, document steps and execution instructions
â€¢ Packaging (`requirements.txt`), finalize code, and push to Git
```

## âš™ï¸ Repository setup & structure steps

Initialize the project

```bash
mkdir criteo-measurement-proto && cd criteo-measurement-proto
git init
python -m venv venv
.\venv\Scripts\activate
pip install --upgrade pip
touch requirements.txt
```

Install dependencies
In `requirements.txt`, list:

```
nginx
pandas
numpy
sqlalchemy
scikit-learn
plotly
dash         # or streamlit
pytest       # for unit tests
```

Then:

```bash
pip install -r requirements.txt
```

```text
criteo-measurement-proto/
â”œâ”€â”€ data/                  # datasets (raw & processed)
â”œâ”€â”€ notebooks/             # exploratory analyses
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ingestion.py       # import and cleaning scripts
â”‚   â”œâ”€â”€ modeling.py        # funnel definition & models
â”‚   â”œâ”€â”€ evaluation.py      # evaluation functions and A/B test
â”‚   â””â”€â”€ dashboard.py       # Dash or Streamlit app
â”œâ”€â”€ tests/                 # pytest unit tests
â”œâ”€â”€ docs/                  # documentation and diagrams
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

## Incremental development

* **Ingestion** (`src/ingestion.py`): read CSV, clean, load into SQLite via SQLAlchemy or store as Parquet.

* **Modeling** (`src/modeling.py`): build the funnel, prepare X, y, train `LogisticRegression`.

* **Evaluation** (`src/evaluation.py`): metrics (accuracy, AUC), proportion test function for a simulated A/B.

* **Dashboard** (`src/dashboard.py`): display interactive funnel, ROC curves, and A/B test results.

* **Tests & quality**

Write simple tests in `tests/` to validate that a sample dataset produces the correct KPIs.

Run:

```bash
pytest --maxfail=1 --disable-warnings -q
```

## Dashboard

Modular Python scripts for ingestion, modeling, evaluation, and dashboard.

A local interactive dashboard (Dash or Streamlit) measuring:

* The full funnel (visits â†’ purchases)

* Predictive model performance

* Simulated feature impact via A/B test

Unit tests ensuring reproducibility.

Documentation (text + diagrams) explaining the pipeline.

## This project covers:

* Large-scale data mining (synthetic logs),

* Scalable pipeline (modular scripts, SQL/Parquet),

* Analyses & tests (funnel, A/B, predictive modeling),

* Visualization and reporting (interactive dashboard),

* Common tools (Python, SQL, scikit-learn, Dash).
